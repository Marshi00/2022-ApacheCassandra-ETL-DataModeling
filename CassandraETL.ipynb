{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4HCxg13sXfp"
      },
      "source": [
        "# Part I. ETL Pipeline for Pre-Processing the Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANTUTFrsXfr"
      },
      "source": [
        "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oWDPU43sXfr"
      },
      "source": [
        "#### Import Python packages "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install cassandra-driver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSUafkVwtstC",
        "outputId": "878c4422-7caf-4d37-e65d-1f61c883c84f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.25.0-cp38-cp38-manylinux1_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting geomet<0.3,>=0.1\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from cassandra-driver) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (7.1.2)\n",
            "Installing collected packages: geomet, cassandra-driver\n",
            "Successfully installed cassandra-driver-3.25.0 geomet-0.2.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KZ9d70jwsXfr"
      },
      "outputs": [],
      "source": [
        "# Import Python packages \n",
        "import datetime\n",
        "import pandas as pd\n",
        "import cassandra\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import json\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbPwIdY_sXfs"
      },
      "source": [
        "#### Creating list of filepaths to process original event csv data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8bJRXpasXfs",
        "outputId": "13921f95-5912-4367-df4f-f040cf593d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/event_data\n",
            "['/content/event_data/2018-11-19-events.csv', '/content/event_data/2018-11-01-events.csv', '/content/event_data/2018-11-23-events.csv', '/content/event_data/2018-11-30-events.csv', '/content/event_data/2018-11-06-events.csv', '/content/event_data/2018-11-22-events.csv', '/content/event_data/2018-11-04-events.csv', '/content/event_data/2018-11-03-events.csv', '/content/event_data/2018-11-02-events.csv', '/content/event_data/2018-11-17-events.csv', '/content/event_data/2018-11-28-events.csv', '/content/event_data/2018-11-13-events.csv', '/content/event_data/2018-11-09-events.csv', '/content/event_data/2018-11-11-events.csv', '/content/event_data/2018-11-20-events.csv', '/content/event_data/2018-11-29-events.csv', '/content/event_data/2018-11-18-events.csv', '/content/event_data/2018-11-08-events.csv', '/content/event_data/2018-11-24-events.csv', '/content/event_data/2018-11-25-events.csv', '/content/event_data/2018-11-10-events.csv', '/content/event_data/2018-11-16-events.csv', '/content/event_data/2018-11-15-events.csv', '/content/event_data/2018-11-21-events.csv', '/content/event_data/2018-11-05-events.csv', '/content/event_data/2018-11-12-events.csv', '/content/event_data/2018-11-26-events.csv', '/content/event_data/2018-11-27-events.csv', '/content/event_data/2018-11-14-events.csv', '/content/event_data/2018-11-07-events.csv']\n"
          ]
        }
      ],
      "source": [
        "# checking your current working directory\n",
        "print(os.getcwd())\n",
        "\n",
        "# Get your current folder and subfolder event data\n",
        "filepath = os.getcwd() + '/event_data'\n",
        "print(filepath)\n",
        "# Create a for loop to create a list of files and collect each filepath\n",
        "for root, dirs, files in os.walk(filepath):\n",
        "    \n",
        "# join the file path and roots with the subdirectories using glob\n",
        "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
        "    print(file_path_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Method - Processing the files to create the data file csv that will be used for Apache Casssandra tables "
      ],
      "metadata": {
        "id": "CcvQ3fIux4Q0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxmjtpCYsXfu",
        "outputId": "2b608355-ee17-4a81-979e-0513171e7118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WedJan110158492023.csv\n"
          ]
        }
      ],
      "source": [
        "# making a time stamp\n",
        "now = datetime.datetime.now()\n",
        "time_stamp = now.strftime(\"%c\").replace(\" \", \"\")\n",
        "time_stamp = time_stamp.replace(\":\", \"\")\n",
        "\n",
        "# for every filepath in the file path list \n",
        "combined_frame = pd.DataFrame()\n",
        "for path in file_path_list:\n",
        "\n",
        "# reading csv file \n",
        "    data = pd.read_csv(path,encoding = 'utf8')\n",
        "    combined_frame = pd.concat([combined_frame, data], ignore_index=True)   \n",
        " # extracting each csv one by one and append it        \n",
        "    #data.to_csv(f\"{time_stamp}.csv\", mode='a', index=False, encoding = 'utf8')\n",
        "\n",
        "# saving the combined frame\n",
        "combined_frame.to_csv(f\"{time_stamp}.csv\", mode='w', index=False, encoding = 'utf8')\n",
        "combined_csv = f\"{time_stamp}.csv\"\n",
        "print(combined_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean DATA , DROP unconstant Data, DROP Unused DATA"
      ],
      "metadata": {
        "id": "8E29xX1S9zfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show numeric output in decimal format e.g., 2.15\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "data_frame = pd.read_csv(combined_csv)"
      ],
      "metadata": {
        "id": "YDwalOOJ_tvg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the Data & Check for Consistency"
      ],
      "metadata": {
        "id": "dVuGCR7hAVcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many rows and columns does df_apps have? What are the column names?\n",
        "# What does the data look like?\n",
        "# Look at a random sample of 5 different rows with\n",
        "print(data_frame.shape)\n",
        "print(data_frame.columns)\n",
        "print(data_frame.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5crr-GGh_v1c",
        "outputId": "3517ea46-156b-49f1-d109-aa0133bde77b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8056, 17)\n",
            "Index(['artist', 'auth', 'firstName', 'gender', 'itemInSession', 'lastName',\n",
            "       'length', 'level', 'location', 'method', 'page', 'registration',\n",
            "       'sessionId', 'song', 'status', 'ts', 'userId'],\n",
            "      dtype='object')\n",
            "              artist       auth firstName gender  itemInSession lastName  \\\n",
            "2568  Tapes \u0018n Tapes  Logged In      Kate      F             13  Harrell   \n",
            "\n",
            "      length level                  location method      page  \\\n",
            "2568  191.63  paid  Lansing-East Lansing, MI    PUT  NextSong   \n",
            "\n",
            "             registration  sessionId                song  status  \\\n",
            "2568 1,540,470,000,000.00        537  Say Back Something     200   \n",
            "\n",
            "                       ts  userId  \n",
            "2568 1,542,130,000,000.00   97.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropping the columns that are not relevant to our queries  "
      ],
      "metadata": {
        "id": "Ac5-y6XnCsNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the cols that are not needed\n",
        "data_frame.drop([\"auth\", \"method\", \"page\", \"registration\", \"status\", \"ts\"], axis=1, inplace=True)\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqeedQG5DBCh",
        "outputId": "0a257099-1139-4469-d802-6a17491cd74c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  artist firstName gender  itemInSession lastName  length  \\\n",
            "0                    NaN      Lily      F              0    Burns     NaN   \n",
            "1  Explosions In The Sky    Adelyn      F              0   Jordan  497.48   \n",
            "2                    NaN    Adelyn      F              1   Jordan     NaN   \n",
            "3                    NaN       NaN    NaN              2      NaN     NaN   \n",
            "4                    NaN       NaN    NaN              3      NaN     NaN   \n",
            "\n",
            "  level                               location  sessionId               song  \\\n",
            "0  free  New York-Newark-Jersey City, NY-NJ-PA        689                NaN   \n",
            "1  free     Chicago-Naperville-Elgin, IL-IN-WI        458  Your Hand In Mine   \n",
            "2  free     Chicago-Naperville-Elgin, IL-IN-WI        458                NaN   \n",
            "3  free                                    NaN        458                NaN   \n",
            "4  free                                    NaN        458                NaN   \n",
            "\n",
            "   userId  \n",
            "0   32.00  \n",
            "1    7.00  \n",
            "2    7.00  \n",
            "3     NaN  \n",
            "4     NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaning the data here"
      ],
      "metadata": {
        "id": "TrGJZOBxD0FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove nun & dublicate values\n",
        "print(f'Missing values for data set?: {data_frame.isna().values.any()}')\n",
        "print(f'Missing values for data set?: {data_frame.isna().values.sum()}')\n",
        "data_frame.dropna(inplace=True)\n",
        "print(f'Missing values for data set?: {data_frame.isna().values.any()}')\n",
        "print(f'Missing values for data set?: {data_frame.isna().values.sum()}')\n",
        "# Remove duplicates\n",
        "print(f'duplicates values for data set?: {data_frame.duplicated().values.any()}')\n",
        "print(f'duplicates values for data set?: {data_frame.duplicated().values.sum()}')\n",
        "print(data_frame.duplicated)  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpOlhHyQD77Q",
        "outputId": "09aa9680-6910-470d-cd66-80003db5c4c2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values for data set?: True\n",
            "Missing values for data set?: 5138\n",
            "Missing values for data set?: False\n",
            "Missing values for data set?: 0\n",
            "duplicates values for data set?: False\n",
            "duplicates values for data set?: 0\n",
            "<bound method DataFrame.duplicated of                                     artist firstName gender  itemInSession  \\\n",
            "1                    Explosions In The Sky    Adelyn      F              0   \n",
            "6     Paul Van Dyk Featuring Jessica Sutta     Layla      F              0   \n",
            "7                               Tim Hughes     Layla      F              1   \n",
            "8     David Cassidy & The Partridge Family     Layla      F              2   \n",
            "9                              Snow Patrol     Layla      F              3   \n",
            "...                                    ...       ...    ...            ...   \n",
            "8050                        The Cat Empire      Lily      F            104   \n",
            "8052                          STRATOVARIUS      Lily      F              1   \n",
            "8053                           The Mantles      Lily      F              2   \n",
            "8054                              Tub Ring     Kaleb      M              0   \n",
            "8055                          Jack Johnson     Kaleb      M              1   \n",
            "\n",
            "     lastName  length level                               location  sessionId  \\\n",
            "1      Jordan  497.48  free     Chicago-Naperville-Elgin, IL-IN-WI        458   \n",
            "6     Griffin  425.66  paid           Lake Havasu City-Kingman, AZ        672   \n",
            "7     Griffin  323.47  paid           Lake Havasu City-Kingman, AZ        672   \n",
            "8     Griffin  227.74  paid           Lake Havasu City-Kingman, AZ        672   \n",
            "9     Griffin  200.93  paid           Lake Havasu City-Kingman, AZ        672   \n",
            "...       ...     ...   ...                                    ...        ...   \n",
            "8050     Koch  307.46  paid     Chicago-Naperville-Elgin, IL-IN-WI        221   \n",
            "8052    Burns  350.75  free  New York-Newark-Jersey City, NY-NJ-PA        349   \n",
            "8053    Burns  226.53  free  New York-Newark-Jersey City, NY-NJ-PA        349   \n",
            "8054     Cook  233.69  free                          Yuba City, CA        213   \n",
            "8055     Cook  173.43  free                          Yuba City, CA        213   \n",
            "\n",
            "                               song  userId  \n",
            "1                 Your Hand In Mine    7.00  \n",
            "6     White Lies (Dave Spoon Remix)   24.00  \n",
            "7                    God of Justice   24.00  \n",
            "8             I'll Meet You Halfway   24.00  \n",
            "9                Crack The Shutters   24.00  \n",
            "...                             ...     ...  \n",
            "8050                    The Chariot   15.00  \n",
            "8052                  Twilight Time   32.00  \n",
            "8053                      Don't Lie   32.00  \n",
            "8054                        Invalid   54.00  \n",
            "8055                     Wrong Turn   54.00  \n",
            "\n",
            "[6820 rows x 11 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### check our data after  cleanning "
      ],
      "metadata": {
        "id": "9zeTSxPwFWyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame.shape)\n",
        "print(data_frame.columns)\n",
        "print(data_frame.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZX60sdmFRhN",
        "outputId": "a2eeef64-fd6d-4773-c6ca-701ff4f674e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6820, 11)\n",
            "Index(['artist', 'firstName', 'gender', 'itemInSession', 'lastName', 'length',\n",
            "       'level', 'location', 'sessionId', 'song', 'userId'],\n",
            "      dtype='object')\n",
            "              artist firstName gender  itemInSession lastName  length level  \\\n",
            "5988  Massive Attack      Lily      F             57     Koch  316.50  paid   \n",
            "\n",
            "                                location  sessionId       song  userId  \n",
            "5988  Chicago-Naperville-Elgin, IL-IN-WI        764  Karmacoma   15.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change Columns type to the desired format"
      ],
      "metadata": {
        "id": "UVXKnuHFYLAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame.describe())\n",
        "print(data_frame.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21om0eI8YU4c",
        "outputId": "79dfe054-48d7-492a-831a-4d98a07c7071"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       itemInSession   length  sessionId   userId\n",
            "count       6,820.00 6,820.00   6,820.00 6,820.00\n",
            "mean           22.76   247.03     599.18    54.68\n",
            "std            23.44   102.98     284.95    28.16\n",
            "min             0.00    15.86       3.00     2.00\n",
            "25%             4.00   197.32     374.00    29.00\n",
            "50%            15.00   232.97     605.00    49.00\n",
            "75%            35.00   274.12     834.00    80.00\n",
            "max           126.00 2,594.87   1,114.00   101.00\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6820 entries, 1 to 8055\n",
            "Data columns (total 11 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   artist         6820 non-null   object \n",
            " 1   firstName      6820 non-null   object \n",
            " 2   gender         6820 non-null   object \n",
            " 3   itemInSession  6820 non-null   int64  \n",
            " 4   lastName       6820 non-null   object \n",
            " 5   length         6820 non-null   float64\n",
            " 6   level          6820 non-null   object \n",
            " 7   location       6820 non-null   object \n",
            " 8   sessionId      6820 non-null   int64  \n",
            " 9   song           6820 non-null   object \n",
            " 10  userId         6820 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(7)\n",
            "memory usage: 639.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame[\"itemInSession\"] = pd.to_numeric(data_frame[\"itemInSession\"])\n",
        "data_frame[\"length\"] = pd.to_numeric(data_frame[\"length\"])\n",
        "data_frame[\"sessionId\"] = pd.to_numeric(data_frame[\"sessionId\"])\n",
        "data_frame[\"userId\"] = pd.to_numeric(data_frame[\"userId\"],downcast='integer' )\n"
      ],
      "metadata": {
        "id": "k1Tug2HUaOY9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### See the new data types and if the data is ready"
      ],
      "metadata": {
        "id": "WcFl3YWBniXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame.describe())\n",
        "print(data_frame.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EX8vb11cGXf",
        "outputId": "cdef4bce-144f-496c-a23f-15ccb3bc12f2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       itemInSession   length  sessionId   userId\n",
            "count       6,820.00 6,820.00   6,820.00 6,820.00\n",
            "mean           22.76   247.03     599.18    54.68\n",
            "std            23.44   102.98     284.95    28.16\n",
            "min             0.00    15.86       3.00     2.00\n",
            "25%             4.00   197.32     374.00    29.00\n",
            "50%            15.00   232.97     605.00    49.00\n",
            "75%            35.00   274.12     834.00    80.00\n",
            "max           126.00 2,594.87   1,114.00   101.00\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6820 entries, 1 to 8055\n",
            "Data columns (total 11 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   artist         6820 non-null   object \n",
            " 1   firstName      6820 non-null   object \n",
            " 2   gender         6820 non-null   object \n",
            " 3   itemInSession  6820 non-null   int64  \n",
            " 4   lastName       6820 non-null   object \n",
            " 5   length         6820 non-null   float64\n",
            " 6   level          6820 non-null   object \n",
            " 7   location       6820 non-null   object \n",
            " 8   sessionId      6820 non-null   int64  \n",
            " 9   song           6820 non-null   object \n",
            " 10  userId         6820 non-null   int8   \n",
            "dtypes: float64(1), int64(2), int8(1), object(7)\n",
            "memory usage: 592.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLHQgVGLsXft"
      },
      "source": [
        "## Method 2 - Processing the files to create the data file csv that will be used for Apache Casssandra tables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYZY6-VPsXft"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# initiating an empty list of rows that will be generated from each file\n",
        "full_data_rows_list = [] \n",
        "    \n",
        "# for every filepath in the file path list \n",
        "for f in file_path_list:\n",
        "\n",
        "# reading csv file \n",
        "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
        "        # creating a csv reader object \n",
        "        csvreader = csv.reader(csvfile) \n",
        "        next(csvreader)\n",
        "        \n",
        " # extracting each data row one by one and append it        \n",
        "        for line in csvreader:\n",
        "            #print(line)\n",
        "            full_data_rows_list.append(line) \n",
        "            \n",
        "# uncomment the code below if you would like to get total number of rows \n",
        "#print(len(full_data_rows_list))\n",
        "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
        "#print(full_data_rows_list)\n",
        "\n",
        "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
        "# Apache Cassandra tables\n",
        "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
        "\n",
        "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
        "    writer = csv.writer(f, dialect='myDialect')\n",
        "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
        "                'level','location','sessionId','song','userId'])\n",
        "    for row in full_data_rows_list:\n",
        "        if (row[0] == ''):\n",
        "            continue\n",
        "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73C0mxFsXfu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# check the number of rows in your csv file\n",
        "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
        "    print(sum(1 for line in f))\n",
        "    \n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjqFK0YisXfv"
      },
      "source": [
        "# Part II. Model & Denormalize the DB for the Needed Queries , Optimizing for Fast, Responsive Reads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI_8I3PFsXfv"
      },
      "source": [
        "## Apache Cassandra code in the cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gZfgUAd5npIv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUt8nu3XsXfv"
      },
      "source": [
        "#### Creating a Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H0StCrzsXfv"
      },
      "outputs": [],
      "source": [
        "# This should make a connection to a Cassandra instance your local machine \n",
        "# (127.0.0.1)\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "cluster = Cluster()\n",
        "\n",
        "# To establish connection and begin executing queries, need a session\n",
        "session = cluster.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-V9HXazsXfv"
      },
      "source": [
        "#### Create Keyspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISG4A3ExsXfw"
      },
      "outputs": [],
      "source": [
        "# TO-DO: Create a Keyspace "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4tg9iZsXfw"
      },
      "source": [
        "#### Set Keyspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4rOq5zrsXfw"
      },
      "outputs": [],
      "source": [
        "# TO-DO: Set KEYSPACE to the keyspace specified above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txX6RlTWsXfw"
      },
      "source": [
        "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhj-TxiGsXfw"
      },
      "source": [
        "## Create queries to ask the following three questions of the data\n",
        "\n",
        "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
        "\n",
        "\n",
        "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
        "    \n",
        "\n",
        "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FOMxo68sXfx"
      },
      "outputs": [],
      "source": [
        "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
        "## sessionId = 338, and itemInSession = 4\n",
        "\n",
        "\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfHjrt54sXfx"
      },
      "outputs": [],
      "source": [
        "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
        "file = 'event_datafile_new.csv'\n",
        "\n",
        "with open(file, encoding = 'utf8') as f:\n",
        "    csvreader = csv.reader(f)\n",
        "    next(csvreader) # skip header\n",
        "    for line in csvreader:\n",
        "## TO-DO: Assign the INSERT statements into the `query` variable\n",
        "        query = \"<ENTER INSERT STATEMENT HERE>\"\n",
        "        query = query + \"<ASSIGN VALUES HERE>\"\n",
        "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
        "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
        "        session.execute(query, (line[#], line[#]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYyJhYuDsXfx"
      },
      "source": [
        "#### Do a SELECT to verify that the data have been inserted into each table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IzFkkIr9sXfx"
      },
      "outputs": [],
      "source": [
        "## TO-DO: Add in the SELECT statement to verify the data was entered into the table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJSt3TasXfy"
      },
      "source": [
        "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1eR_PFOsXfy"
      },
      "outputs": [],
      "source": [
        "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
        "## for userid = 10, sessionid = 182\n",
        "\n",
        "\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcSNRZISsXfy"
      },
      "outputs": [],
      "source": [
        "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
        "\n",
        "\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36h7n5cdsXfy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBzyRhn0sXfy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_ylfuOsXfy"
      },
      "source": [
        "### Drop the tables before closing out the sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8KwE2p9sXfy"
      },
      "outputs": [],
      "source": [
        "## TO-DO: Drop the table before closing out the sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvLCPyD2sXfz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CRWGbLosXfz"
      },
      "source": [
        "### Close the session and cluster connection¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCztFn7WsXfz"
      },
      "outputs": [],
      "source": [
        "session.shutdown()\n",
        "cluster.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcZ6pubQsXfz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYdbU2ugsXfz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}