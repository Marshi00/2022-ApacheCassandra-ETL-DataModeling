{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4HCxg13sXfp"
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zANTUTFrsXfr"
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oWDPU43sXfr"
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSUafkVwtstC",
    "outputId": "878c4422-7caf-4d37-e65d-1f61c883c84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in c:\\users\\marsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.25.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\marsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cassandra-driver) (1.16.0)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\marsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\marsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\marsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Marsh\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KZ9d70jwsXfr"
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import datetime\n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbPwIdY_sXfs"
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8bJRXpasXfs",
    "outputId": "13921f95-5912-4367-df4f-f040cf593d7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marsh\\Desktop\\2022-ApacheCassandra-ETL-DataModeling\n",
      "C:\\Users\\Marsh\\Desktop\\2022-ApacheCassandra-ETL-DataModeling/event_data\n",
      "['C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-01-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-02-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-03-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-04-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-05-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-06-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-07-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-08-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-09-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-10-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-11-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-12-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-13-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-14-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-15-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-16-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-17-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-18-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-19-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-20-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-21-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-22-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-23-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-24-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-25-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-26-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-27-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-28-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-29-events.csv', 'C:\\\\Users\\\\Marsh\\\\Desktop\\\\2022-ApacheCassandra-ETL-DataModeling/event_data\\\\2018-11-30-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "print(filepath)\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcvQ3fIux4Q0"
   },
   "source": [
    "## Pandas Method - Processing the files to create the data file csv that will be used for Apache Casssandra tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxmjtpCYsXfu",
    "outputId": "2b608355-ee17-4a81-979e-0513171e7118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FriJan131330452023.csv\n"
     ]
    }
   ],
   "source": [
    "# making a time stamp\n",
    "now = datetime.datetime.now()\n",
    "time_stamp = now.strftime(\"%c\").replace(\" \", \"\")\n",
    "time_stamp = time_stamp.replace(\":\", \"\")\n",
    "\n",
    "# for every filepath in the file path list \n",
    "combined_frame = pd.DataFrame()\n",
    "for path in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    data = pd.read_csv(path,encoding = 'utf8')\n",
    "    combined_frame = pd.concat([combined_frame, data], ignore_index=True)   \n",
    " # extracting each csv one by one and append it        \n",
    "    #data.to_csv(f\"{time_stamp}.csv\", mode='a', index=False, encoding = 'utf8')\n",
    "\n",
    "# saving the combined frame\n",
    "combined_frame.to_csv(f\"{time_stamp}.csv\", mode='w', index=False, encoding = 'utf8')\n",
    "combined_csv = f\"{time_stamp}.csv\"\n",
    "print(combined_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E29xX1S9zfK"
   },
   "source": [
    "### Clean DATA , DROP unconstant Data, DROP Unused DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YDwalOOJ_tvg"
   },
   "outputs": [],
   "source": [
    "# Show numeric output in decimal format e.g., 2.15\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "data_frame = pd.read_csv(combined_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVuGCR7hAVcd"
   },
   "source": [
    "#### Explore the Data & Check for Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5crr-GGh_v1c",
    "outputId": "3517ea46-156b-49f1-d109-aa0133bde77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8056, 17)\n",
      "Index(['artist', 'auth', 'firstName', 'gender', 'itemInSession', 'lastName',\n",
      "       'length', 'level', 'location', 'method', 'page', 'registration',\n",
      "       'sessionId', 'song', 'status', 'ts', 'userId'],\n",
      "      dtype='object')\n",
      "     artist       auth firstName gender  itemInSession lastName  length level  \\\n",
      "3567  Hevia  Logged In    Aleena      F              3    Kirby  256.47  paid   \n",
      "\n",
      "                      location method      page         registration  \\\n",
      "3567  Waterloo-Cedar Falls, IA    PUT  NextSong 1,541,020,000,000.00   \n",
      "\n",
      "      sessionId                 song  status                   ts  userId  \n",
      "3567        637  Fandangu Los Llobos     200 1,542,320,000,000.00   44.00  \n"
     ]
    }
   ],
   "source": [
    "# How many rows and columns does df_apps have? What are the column names?\n",
    "# What does the data look like?\n",
    "# Look at a random sample of 5 different rows with\n",
    "print(data_frame.shape)\n",
    "print(data_frame.columns)\n",
    "print(data_frame.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac5-y6XnCsNV"
   },
   "source": [
    "#### Dropping the columns that are not relevant to our queries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqeedQG5DBCh",
    "outputId": "0a257099-1139-4469-d802-6a17491cd74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    artist firstName gender  itemInSession lastName  length level  \\\n",
      "0      NaN    Walter      M              0     Frye     NaN  free   \n",
      "1      NaN    Kaylee      F              0  Summers     NaN  free   \n",
      "2  Des'ree    Kaylee      F              1  Summers  246.31  free   \n",
      "3      NaN    Kaylee      F              2  Summers     NaN  free   \n",
      "4  Mr Oizo    Kaylee      F              3  Summers  144.04  free   \n",
      "\n",
      "                            location  sessionId          song  userId  \n",
      "0  San Francisco-Oakland-Hayward, CA         38           NaN   39.00  \n",
      "1        Phoenix-Mesa-Scottsdale, AZ        139           NaN    8.00  \n",
      "2        Phoenix-Mesa-Scottsdale, AZ        139  You Gotta Be    8.00  \n",
      "3        Phoenix-Mesa-Scottsdale, AZ        139           NaN    8.00  \n",
      "4        Phoenix-Mesa-Scottsdale, AZ        139       Flat 55    8.00  \n"
     ]
    }
   ],
   "source": [
    "# drop the cols that are not needed\n",
    "data_frame.drop([\"auth\", \"method\", \"page\", \"registration\", \"status\", \"ts\"], axis=1, inplace=True)\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrGJZOBxD0FX"
   },
   "source": [
    "#### Cleaning the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpOlhHyQD77Q",
    "outputId": "09aa9680-6910-470d-cd66-80003db5c4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for data set?: True\n",
      "Missing values for data set?: 5138\n",
      "Missing values for data set?: False\n",
      "Missing values for data set?: 0\n",
      "duplicates values for data set?: False\n",
      "duplicates values for data set?: 0\n",
      "<bound method DataFrame.duplicated of                  artist firstName gender  itemInSession lastName  length  \\\n",
      "2               Des'ree    Kaylee      F              1  Summers  246.31   \n",
      "4               Mr Oizo    Kaylee      F              3  Summers  144.04   \n",
      "5            Tamba Trio    Kaylee      F              4  Summers  177.19   \n",
      "6        The Mars Volta    Kaylee      F              5  Summers  380.42   \n",
      "7     Infected Mushroom    Kaylee      F              6  Summers  440.27   \n",
      "...                 ...       ...    ...            ...      ...     ...   \n",
      "8050       Foo Fighters     Rylan      M             57   George  271.39   \n",
      "8051         Timbiriche     Rylan      M             58   George  202.61   \n",
      "8052   A Perfect Circle     Rylan      M             59   George  206.05   \n",
      "8053           Anberlin     Rylan      M             60   George  348.68   \n",
      "8055          Deas Vail    Elijah      M              0    Davis  237.69   \n",
      "\n",
      "     level                     location  sessionId  \\\n",
      "2     free  Phoenix-Mesa-Scottsdale, AZ        139   \n",
      "4     free  Phoenix-Mesa-Scottsdale, AZ        139   \n",
      "5     free  Phoenix-Mesa-Scottsdale, AZ        139   \n",
      "6     free  Phoenix-Mesa-Scottsdale, AZ        139   \n",
      "7     free  Phoenix-Mesa-Scottsdale, AZ        139   \n",
      "...    ...                          ...        ...   \n",
      "8050  paid        Birmingham-Hoover, AL       1076   \n",
      "8051  paid        Birmingham-Hoover, AL       1076   \n",
      "8052  paid        Birmingham-Hoover, AL       1076   \n",
      "8053  paid        Birmingham-Hoover, AL       1076   \n",
      "8055  free  Detroit-Warren-Dearborn, MI        985   \n",
      "\n",
      "                                       song  userId  \n",
      "2                              You Gotta Be    8.00  \n",
      "4                                   Flat 55    8.00  \n",
      "5              Quem Quiser Encontrar O Amor    8.00  \n",
      "6                                 Eriatarka    8.00  \n",
      "7                           Becoming Insane    8.00  \n",
      "...                                     ...     ...  \n",
      "8050                          The Pretender   16.00  \n",
      "8051                        Besos De Ceniza   16.00  \n",
      "8052                                   Rose   16.00  \n",
      "8053                           The Haunting   16.00  \n",
      "8055  Anything You Say (Unreleased Version)    5.00  \n",
      "\n",
      "[6820 rows x 11 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Remove nun & dublicate values\n",
    "print(f'Missing values for data set?: {data_frame.isna().values.any()}')\n",
    "print(f'Missing values for data set?: {data_frame.isna().values.sum()}')\n",
    "data_frame.dropna(inplace=True)\n",
    "print(f'Missing values for data set?: {data_frame.isna().values.any()}')\n",
    "print(f'Missing values for data set?: {data_frame.isna().values.sum()}')\n",
    "# Remove duplicates\n",
    "print(f'duplicates values for data set?: {data_frame.duplicated().values.any()}')\n",
    "print(f'duplicates values for data set?: {data_frame.duplicated().values.sum()}')\n",
    "print(data_frame.duplicated)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zeTSxPwFWyV"
   },
   "source": [
    "#### check our data after  cleanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZX60sdmFRhN",
    "outputId": "a2eeef64-fd6d-4773-c6ca-701ff4f674e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6820, 11)\n",
      "Index(['artist', 'firstName', 'gender', 'itemInSession', 'lastName', 'length',\n",
      "       'level', 'location', 'sessionId', 'song', 'userId'],\n",
      "      dtype='object')\n",
      "        artist firstName gender  itemInSession lastName  length level  \\\n",
      "6547  Deadmau5     Tegan      F              6   Levine  429.95  paid   \n",
      "\n",
      "                         location  sessionId    song  userId  \n",
      "6547  Portland-South Portland, ME        933  Arguru   80.00  \n"
     ]
    }
   ],
   "source": [
    "print(data_frame.shape)\n",
    "print(data_frame.columns)\n",
    "print(data_frame.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVXKnuHFYLAG"
   },
   "source": [
    "#### Change Columns type to the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21om0eI8YU4c",
    "outputId": "79dfe054-48d7-492a-831a-4d98a07c7071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       itemInSession   length  sessionId   userId\n",
      "count       6,820.00 6,820.00   6,820.00 6,820.00\n",
      "mean           22.76   247.03     599.18    54.68\n",
      "std            23.44   102.98     284.95    28.16\n",
      "min             0.00    15.86       3.00     2.00\n",
      "25%             4.00   197.32     374.00    29.00\n",
      "50%            15.00   232.97     605.00    49.00\n",
      "75%            35.00   274.12     834.00    80.00\n",
      "max           126.00 2,594.87   1,114.00   101.00\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6820 entries, 2 to 8055\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         6820 non-null   object \n",
      " 1   firstName      6820 non-null   object \n",
      " 2   gender         6820 non-null   object \n",
      " 3   itemInSession  6820 non-null   int64  \n",
      " 4   lastName       6820 non-null   object \n",
      " 5   length         6820 non-null   float64\n",
      " 6   level          6820 non-null   object \n",
      " 7   location       6820 non-null   object \n",
      " 8   sessionId      6820 non-null   int64  \n",
      " 9   song           6820 non-null   object \n",
      " 10  userId         6820 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 639.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.describe())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k1Tug2HUaOY9"
   },
   "outputs": [],
   "source": [
    "data_frame[\"itemInSession\"] = pd.to_numeric(data_frame[\"itemInSession\"])\n",
    "data_frame[\"length\"] = pd.to_numeric(data_frame[\"length\"])\n",
    "data_frame[\"sessionId\"] = pd.to_numeric(data_frame[\"sessionId\"])\n",
    "data_frame[\"userId\"] = pd.to_numeric(data_frame[\"userId\"],downcast='integer' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcFl3YWBniXF"
   },
   "source": [
    "#### See the new data types and if the data is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EX8vb11cGXf",
    "outputId": "cdef4bce-144f-496c-a23f-15ccb3bc12f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       itemInSession   length  sessionId   userId\n",
      "count       6,820.00 6,820.00   6,820.00 6,820.00\n",
      "mean           22.76   247.03     599.18    54.68\n",
      "std            23.44   102.98     284.95    28.16\n",
      "min             0.00    15.86       3.00     2.00\n",
      "25%             4.00   197.32     374.00    29.00\n",
      "50%            15.00   232.97     605.00    49.00\n",
      "75%            35.00   274.12     834.00    80.00\n",
      "max           126.00 2,594.87   1,114.00   101.00\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6820 entries, 2 to 8055\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         6820 non-null   object \n",
      " 1   firstName      6820 non-null   object \n",
      " 2   gender         6820 non-null   object \n",
      " 3   itemInSession  6820 non-null   int64  \n",
      " 4   lastName       6820 non-null   object \n",
      " 5   length         6820 non-null   float64\n",
      " 6   level          6820 non-null   object \n",
      " 7   location       6820 non-null   object \n",
      " 8   sessionId      6820 non-null   int64  \n",
      " 9   song           6820 non-null   object \n",
      " 10  userId         6820 non-null   int8   \n",
      "dtypes: float64(1), int64(2), int8(1), object(7)\n",
      "memory usage: 592.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.describe())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv(f\"event_datafile_new_{time_stamp}.csv\", mode='w', index=False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLHQgVGLsXft",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 2 - Processing the files to create the data file csv that will be used for Apache Casssandra tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYZY6-VPsXft"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P73C0mxFsXfu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjqFK0YisXfv"
   },
   "source": [
    "# Part II. Model & Denormalize the DB for the Needed Queries , Optimizing for Fast, Responsive Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI_8I3PFsXfv"
   },
   "source": [
    "## Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZfgUAd5npIv"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUt8nu3XsXfv"
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0H0StCrzsXfv"
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "try: \n",
    "    #cluster = Cluster(['127.0.0.1']) #If you have a locally installed Apache Cassandra instance\n",
    "    cluster = Cluster(['127.0.0.1'], port='1')\n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    session = cluster.connect()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-V9HXazsXfv"
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ISG4A3ExsXfw"
   },
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS cass_etl \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G4tg9iZsXfw"
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "G4rOq5zrsXfw"
   },
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace(\"cass_etl\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txX6RlTWsXfw"
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhj-TxiGsXfw"
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "9FOMxo68sXfx"
   },
   "outputs": [],
   "source": [
    "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query = \"CREATE TABLE IF NOT EXISTS music_app_history\"\n",
    "query = query + \"\"\"(artist TEXT, song TEXT,\n",
    "                    length FLOAT, \n",
    "                    sessionId INT, itemInSession INT, \n",
    "                    PRIMARY KEY (sessionId, itemInSession))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CfHjrt54sXfx"
   },
   "outputs": [],
   "source": [
    "for index, row in data_frame.iterrows():   \n",
    "    query = \"INSERT INTO music_app_history (sessionId, itemInSession, artist, song, length)\"\n",
    "    query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "    try:\n",
    "        session.execute(query, (row[\"sessionId\"], row[\"itemInSession\"], row[\"artist\"], row[\"song\"], row[\"length\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_app_history (sessionId, itemInSession, artist, song, length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n",
    "\"\"\"        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYyJhYuDsXfx"
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IzFkkIr9sXfx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                             song  length  sessionid  \\\n",
      "0  Faithless  Music Matters (Mark Knight Dub)  495.31        338   \n",
      "\n",
      "   iteminsession  \n",
      "0              4  \n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Add in the SELECT statement to verify the data was entered into the table\n",
    "query = \"SELECT artist, song, length, sessionId , itemInSession FROM music_app_history WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "try:\n",
    "    results = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df = pd.DataFrame(results._current_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znJSt3TasXfy"
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "k1eR_PFOsXfy"
   },
   "outputs": [],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_app_history\"       \n",
    "query = query + \"\"\"(artist TEXT, song TEXT, firstName TEXT, lastName TEXT , \n",
    "                    sessionId INT, itemInSession INT, userId INT, \n",
    "                    PRIMARY KEY ((userId, sessionId), itemInSession))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e :\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "36h7n5cdsXfy"
   },
   "outputs": [],
   "source": [
    "for index, row in data_frame.iterrows():   \n",
    "    query = \"INSERT INTO user_app_history (userId, sessionId, itemInSession, artist, song, firstName, lastName)\"\n",
    "    query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "    try:\n",
    "        session.execute(query, (row[\"userId\"], row[\"sessionId\"], row[\"itemInSession\"], row[\"artist\"], row[\"song\"], row[\"firstName\"], row[\"lastName\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_app_history (userId, sessionId, itemInSession, artist, song, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              artist                                               song  \\\n",
      "0   Down To The Bone                                 Keep On Keepin' On   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2  Sebastien Tellier                                          Kilometer   \n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "\n",
      "  firstname lastname  \n",
      "0    Sylvie     Cruz  \n",
      "1    Sylvie     Cruz  \n",
      "2    Sylvie     Cruz  \n",
      "3    Sylvie     Cruz  \n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song, firstName, lastName FROM user_app_history WHERE userId = 10 AND sessionId = 182\"\n",
    "try:\n",
    "    results = session.execute(query)\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "df = pd.DataFrame(results._current_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "fcSNRZISsXfy"
   },
   "outputs": [],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_info\"       \n",
    "query = query + \"\"\"(song TEXT, firstName TEXT, lastName TEXT , \n",
    "                    userId INT, \n",
    "                    PRIMARY KEY (song,userId))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "jBzyRhn0sXfy"
   },
   "outputs": [],
   "source": [
    "for index, row in data_frame.iterrows():   \n",
    "    query = \"INSERT INTO user_info (userId, song, firstName, lastName)\"\n",
    "    query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "    try:\n",
    "        session.execute(query, (row[\"userId\"], row[\"song\"], row[\"firstName\"], row[\"lastName\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_users (song_title, user_id, first_name, last_name)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    firstname lastname\n",
      "0  Jacqueline    Lynch\n",
      "1       Tegan   Levine\n",
      "2        Sara  Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT firstName, lastName FROM user_info WHERE  song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    results = session.execute(query)\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "df = pd.DataFrame(results._current_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN_ylfuOsXfy"
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8KwE2p9sXfy"
   },
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvLCPyD2sXfz"
   },
   "outputs": [],
   "source": [
    "query = \"drop table music_app_history\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exceptio\n",
    "\n",
    "query = \"drop table user_app_history\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exceptio\n",
    "\n",
    "query = \"drop table user_info\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#execute(\"UPDATE limit_data set value = %s where user_id = %s and limit_data.key = %s\",(0,session['user_id'],'limit_download_result'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CRWGbLosXfz"
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCztFn7WsXfz"
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcZ6pubQsXfz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYdbU2ugsXfz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
